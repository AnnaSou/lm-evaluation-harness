{
  "global_mmlu": {
    "hf_dataset": "CohereLabs/Global-MMLU",
    "category": "regional_knowledge",
    "language_count": {
      "am": 14042,
      "ar": 14042,
      "bn": 14042,
      "cs": 14042,
      "de": 14042,
      "el": 14042,
      "en": 14042,
      "es": 14042,
      "fa": 14042,
      "fil": 14042,
      "fr": 14042,
      "ha": 14042,
      "he": 14042,
      "hi": 14042,
      "id": 14042,
      "ig": 14042,
      "it": 14042,
      "ja": 14042,
      "ko": 14042,
      "ky": 14042,
      "lt": 14042,
      "mg": 14042,
      "ms": 14042,
      "ne": 14042,
      "nl": 14042,
      "ny": 14042,
      "pl": 14042,
      "pt": 14042,
      "ro": 14042,
      "ru": 14042,
      "si": 14042,
      "sn": 14042,
      "so": 14042,
      "sr": 14042,
      "sv": 14042,
      "sw": 14042,
      "te": 14042,
      "tr": 14042,
      "uk": 14042,
      "vi": 14042,
      "yo": 14042,
      "zh": 14042
    }
  },
  "hellaswag_multilingual": {
    "hf_dataset": "alexandrainst/m_hellaswag",
    "category": "reasoning",
    "language_count": {
      "ar": 9176,
      "bn": 9242,
      "ca": 9211,
      "da": 9305,
      "de": 9368,
      "es": 9374,
      "eu": 9255,
      "fr": 9338,
      "gu": 8803,
      "hi": 9416,
      "hr": 9471,
      "hu": 9119,
      "hy": 8632,
      "id": 9314,
      "it": 9193,
      "kn": 8862,
      "ml": 8933,
      "mr": 9279,
      "ne": 9318,
      "nl": 9265,
      "pt": 9229,
      "ro": 9245,
      "ru": 9272,
      "sk": 9485,
      "sr": 9449,
      "sv": 9122,
      "ta": 8413,
      "te": 8724,
      "uk": 9409,
      "vi": 9162,
      "zh": null,
      "en": 9368,
      "is": 9368,
      "nb": 9368
    }
  },
  "truthfulqa_multilingual": {
    "hf_dataset": "alexandrainst/m_truthfulqa",
    "category": "reasoning",
    "language_count": {
      "ar": 773,
      "bn": 781,
      "ca": 777,
      "da": 781,
      "de": 788,
      "es": 789,
      "eu": 774,
      "fr": 787,
      "gu": 731,
      "hi": 773,
      "hr": 769,
      "hu": 771,
      "hy": 553,
      "id": 778,
      "it": 783,
      "kn": 678,
      "ml": 694,
      "mr": 764,
      "ne": 774,
      "nl": 785,
      "pt": 788,
      "ro": 779,
      "ru": 788,
      "sk": 778,
      "sr": 785,
      "sv": 774,
      "ta": 743,
      "te": 705,
      "uk": 770,
      "vi": 785,
      "zh": 788
    }
  },
  "cultural_bench": {
    "hf_dataset": "kellycyy/CulturalBench",
    "category": "regional_knowledge",
    "language_count": {
      "CulturalBench-Hard": {
        "China": 236,
        "South Africa": 232,
        "Japan": 212,
        "Mexico": 196,
        "India": 184,
        "Philippines": 180,
        "South Korea": 164,
        "Spain": 160,
        "Turkey": 152,
        "Iran": 148,
        "Hong Kong": 144,
        "Italy": 144,
        "Argentina": 140,
        "Germany": 128,
        "Russia": 120,
        "Vietnam": 108,
        "Thailand": 108,
        "Indonesia": 104,
        "Czech Republic": 100,
        "Brazil": 100,
        "Netherlands": 100,
        "United Kingdom": 100,
        "Bangladesh": 100,
        "Poland": 96,
        "Singapore": 92,
        "Nigeria": 88,
        "Lebanon": 88,
        "Chile": 88,
        "Taiwan": 88,
        "Nepal": 84,
        "Ukraine": 84,
        "United States": 80,
        "Egypt": 80,
        "Peru": 76,
        "Morocco": 68,
        "Zimbabwe": 68,
        "Saudi Arabia": 68,
        "Romania": 60,
        "Australia": 60,
        "Pakistan": 56,
        "France": 56,
        "Israel": 52,
        "New Zealand": 44,
        "Malaysia": 44,
        "Canada": 28
      },
      "CulturalBench-Easy": {
        "China": 59,
        "South Africa": 58,
        "Japan": 53,
        "Mexico": 49,
        "India": 46,
        "Philippines": 45,
        "South Korea": 41,
        "Spain": 40,
        "Turkey": 38,
        "Iran": 37,
        "Hong Kong": 36,
        "Italy": 36,
        "Argentina": 35,
        "Germany": 32,
        "Russia": 30,
        "Vietnam": 27,
        "Thailand": 27,
        "Indonesia": 26,
        "Czech Republic": 25,
        "Brazil": 25,
        "Netherlands": 25,
        "United Kingdom": 25,
        "Bangladesh": 25,
        "Poland": 24,
        "Singapore": 23,
        "Nigeria": 22,
        "Lebanon": 22,
        "Chile": 22,
        "Taiwan": 22,
        "Nepal": 21,
        "Ukraine": 21,
        "United States": 20,
        "Egypt": 20,
        "Peru": 19,
        "Morocco": 17,
        "Zimbabwe": 17,
        "Saudi Arabia": 17,
        "Romania": 15,
        "Australia": 15,
        "Pakistan": 14,
        "France": 14,
        "Israel": 13,
        "New Zealand": 11,
        "Malaysia": 11,
        "Canada": 7
      }
    }
  },
  "blend": {
    "hf_dataset": "nayeon212/BLEnD",
    "category": "regional_knowledge",
    "language_count": {
      "Ethiopia": 22712,
      "South_Korea": 21439,
      "Assam": 21293,
      "Mexico": 20513,
      "China": 20410,
      "Greece": 20383,
      "Algeria": 20364,
      "Azerbaijan": 19932,
      "Iran": 19371,
      "Spain": 19280,
      "Indonesia": 18417,
      "North_Korea": 17005,
      "UK": 16723,
      "US": 16491,
      "Northern_Nigeria": 16317,
      "West_Java": 15289
    }
  },
  "polyglotoxicityprompts_full": {
    "hf_dataset": "ToxicityPrompts/PolygloToxicityPrompts",
    "category": "safety",
    "language_count": {
      "full": {
        "ar": 25000,
        "cs": 25000,
        "de": 25000,
        "en": 25000,
        "es": 25000,
        "fr": 25000,
        "hi": 25000,
        "id": 25000,
        "it": 25000,
        "ja": 25000,
        "ko": 25000,
        "nl": 25000,
        "pl": 25000,
        "pt": 25000,
        "ru": 25000,
        "sv": 25000,
        "zh": 25000
      },
      "small": {
        "ar": 5000,
        "cs": 5000,
        "de": 5000,
        "en": 5000,
        "es": 5000,
        "fr": 5000,
        "hi": 5000,
        "id": 5000,
        "it": 5000,
        "ja": 5000,
        "ko": 5000,
        "nl": 5000,
        "pl": 5000,
        "pt": 5000,
        "ru": 5000,
        "sv": 5000,
        "zh": 5000
      },
      "wildchat": {
        "ar": 1000,
        "cs": 1000,
        "de": 1000,
        "en": 1000,
        "es": 1000,
        "fr": 1000,
        "hi": 1000,
        "id": 1000,
        "it": 1000,
        "ja": 1000,
        "ko": 1000,
        "nl": 1000,
        "pl": 1000,
        "pt": 1000,
        "ru": 1000,
        "sv": 1000,
        "zh": 1000
      }
    }
  },
  "aya_redteaming": {
    "hf_dataset": "CohereLabs/aya_redteaming",
    "category": "safety",
    "language_count": {
      "arabic": 900,
      "english": 987,
      "filipino": 1009,
      "french": 813,
      "hindi": 915,
      "russian": 1007,
      "serbian": 1006,
      "spanish": 782
    }
  },
  "multijail": {
    "hf_dataset": "DAMO-NLP-SG/MultiJail",
    "category": "safety",
    "language_count": {
      "en": 315,
      "zh": 315,
      "it": 315,
      "vi": 315,
      "ar": 315,
      "ko": 315,
      "th": 315,
      "bn": 315,
      "sw": 315,
      "jv": 315
    }
  }
}